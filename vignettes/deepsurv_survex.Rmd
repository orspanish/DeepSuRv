---
title: "deepsurv_survex"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{deepsurv_survex}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>")
```

```{r setup}
library(DeepSuRv)
library(torch)
library(survival)
library(survex)
```

# Lung data from survival package
```{r}
# Prepare data
X <- lung[, c(1, 4, 5, 6, 7, 8, 9, 10)]
complete_rows <- which(rowSums(is.na(X)) == 0)
X <- X[complete_rows, ]
dat <- lung[complete_rows, ]
event <- ifelse(dat$status == 2, 0, 1)

# Standardize
X_scaled <- scale(X)

train_data <- list(
  x = torch_tensor(as.matrix(X_scaled), dtype = torch_float()),
  time = torch_tensor(dat$time, dtype = torch_float()),
  event = torch_tensor(event, dtype = torch_float())
)

# Order by descending time
order_idx <- order(as.numeric(train_data$time), decreasing = TRUE)
train_data$x <- train_data$x[order_idx, ]
train_data$time <- train_data$time[order_idx]
train_data$event <- train_data$event[order_idx]

# Initialize model
model <- DeepSuRv(
  n_in = ncol(X_scaled),
  hidden_layers = c(16),
  activation = "relu",
  dropout = 0,
  standardize = FALSE,   # already standardized manually
  learning_rate = 0.01
)

# Train
model$train_model(
  train_data = train_data,
  n_epochs = 50,
  early_stopping = FALSE,
  verbose = TRUE
)

# Predict
risk_scores <- model$predict_risk(X_scaled)
head(risk_scores)
```

Create explainer function for DeepSurv model
```{r}
explainer <- make_deepsurv_explainer(model, dat, 'time', 'status')
```

Generate model profile and feature importance plot
```{r}
if (interactive()) {
  model_profile(explainer, output_type = "survival", variables = c("age", "sex"))
  plot(model_parts(explainer))
}
```

# Veteran data from survival package
```{r survex-demo, eval = FALSE}
# Prepare data
X <- veteran[, c(1, 2, 5, 6, 7, 8)]
complete_rows <- which(rowSums(is.na(X)) == 0)
X <- X[complete_rows, ]
dat <- veteran[complete_rows, c(1, 3, 4, 5, 6, 7, 8)]
event <- dat$status

# Standardize
X_scaled <- unname(scale(X[, c(1, 3, 4, 5, 6)]))

train_data <- list(
  x = torch_tensor(as.matrix(X_scaled), dtype = torch_float()),
  time = torch_tensor(dat$time, dtype = torch_float()),
  event = torch_tensor(event, dtype = torch_float())
)

# Order by descending time
order_idx <- order(as.numeric(train_data$time), decreasing = TRUE)
train_data$x <- train_data$x[order_idx, ]
train_data$time <- train_data$time[order_idx]
train_data$event <- train_data$event[order_idx]

# Initialize model
model <- DeepSuRv(
  n_in = ncol(X_scaled),
  hidden_layers = c(16),
  activation = "relu",
  dropout = 0,
  standardize = FALSE,   # already standardized manually
  learning_rate = 0.01
)

# Train without early stopping for now
model$train_model(
  train_data = train_data,
  n_epochs = 50,
  early_stopping = FALSE,
  verbose = TRUE
)

# Predict
risk_scores <- model$predict_risk(X_scaled)
head(risk_scores)

# Create explainer
explainer <- make_deepsurv_explainer(model, dat, 'time', 'status')

# Survex integration
model_profile(explainer, output_type = "survival", variables = c("trt", "age"))
plot(model_parts(explainer))

```

